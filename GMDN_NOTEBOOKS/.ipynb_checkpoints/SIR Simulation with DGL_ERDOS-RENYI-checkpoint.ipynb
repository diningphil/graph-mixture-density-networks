{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "\n",
    "# Initialize the SIR epidemic model.\n",
    "SUSCEPTIBLE = 0\n",
    "INFECTED = 1\n",
    "RECOVERED = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_with_states(graph):\n",
    "    plt.figure()\n",
    "    nx.draw(graph.to_networkx(node_attrs=['STATE']), node_size=50, cmap=plt.cm.Pastel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the state of the network\n",
    "def init_graph(g, initial_probability_of_infection):\n",
    "    N = g.number_of_nodes()\n",
    "    initial_states = (torch.rand(N) < initial_probability_of_infection).int()\n",
    "    if torch.sum(initial_states) == 0:\n",
    "        initial_states[random.randint(0,N-1)] = 1\n",
    "    g.ndata['STATE'] = initial_states\n",
    "    return initial_states.int().tolist()\n",
    "\n",
    "def network_state(g):\n",
    "    N = g.number_of_nodes()\n",
    "    susceptible = torch.sum(g.ndata['STATE'] == SUSCEPTIBLE)\n",
    "    infected = torch.sum(g.ndata['STATE'] == INFECTED)\n",
    "    return susceptible, infected\n",
    "    # print(f\"There are {susceptible} susceptible and {infected} infected people. Total number is {N}\")\n",
    "    \n",
    "def create_erdos_renyi_graph(no_nodes, p):\n",
    "    graph = nx.erdos_renyi_graph(no_nodes, p)\n",
    "    graph = dgl.DGLGraph(graph)\n",
    "    init_graph(graph, 0)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_message_func(beta, edges):\n",
    "    \n",
    "    # if the source node is infected, sample the probability to infect the destination node.\n",
    "    src_edge_infected = edges.src['STATE'] == INFECTED  # this variable contains duplicates of source nodes that are infected\n",
    "    dst_edge_susceptible = edges.dst['STATE'] == SUSCEPTIBLE  # this variable contains duplicates of destination nodes that are susceptible\n",
    "    \n",
    "    # Compute potential targets for all infected nodes\n",
    "    potential_targets = torch.logical_and(src_edge_infected, dst_edge_susceptible)\n",
    "    no_potential_targets = torch.sum(potential_targets)\n",
    "    \n",
    "    will_infect_dest = (torch.randn(no_potential_targets) < beta)\n",
    "    \n",
    "    infections = torch.zeros(edges.src['STATE'].shape[0], dtype=torch.bool)\n",
    "    infections[potential_targets] = will_infect_dest  # at least one message should be 1 to infect the destination\n",
    "    \n",
    "    return {'infections' : infections}\n",
    "\n",
    "def SIR_reduce_func(gamma, nodes):\n",
    "    \n",
    "    to_be_infected = torch.sum(nodes.mailbox['infections'], dim=1)\n",
    "    to_be_infected = to_be_infected >= 1  # if at least one neighbor spreads the infection, then the susceptible node will be infected\n",
    "\n",
    "    will_recover = (torch.randn(nodes.data['STATE'].shape[0]) < gamma)  # compute the probability that a node will recover. Apply it to already infected nodes only \n",
    "    \n",
    "    susceptible = nodes.data['STATE'] == SUSCEPTIBLE  # index tensor of susceptible nodes\n",
    "    infected = nodes.data['STATE'] == INFECTED  # index tensor of infected nodes\n",
    "    recovered = nodes.data['STATE'] == RECOVERED  # index tensor of recovered nodes\n",
    "    \n",
    "    # S -> I\n",
    "    StoI = torch.logical_and(susceptible, to_be_infected)\n",
    "    no_new_infected = torch.sum(StoI)\n",
    "    \n",
    "    # I -> R\n",
    "    ItoR = torch.logical_and(infected, will_recover)\n",
    "    no_new_recovered = torch.sum(ItoR)\n",
    "    # print(f\"Nodes in batch is {nodes.mailbox['infections'].shape[0]}, number of infected is {no_new_infected}, new recovered are {no_new_recovered}\")\n",
    "    \n",
    "    new_states = nodes.data['STATE']\n",
    "    if no_new_infected > 0:\n",
    "        new_states[StoI] = INFECTED\n",
    "    if no_new_recovered > 0:\n",
    "        new_states[ItoR] = RECOVERED\n",
    "    return {'STATE' : new_states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_batch(g):\n",
    "    g.send(g.edges())\n",
    "    g.recv(g.nodes())\n",
    "\n",
    "def simulate_SIR(graph, initial_probability_of_infection, no_iterations=30):\n",
    "    first_infected = init_graph(graph, initial_probability_of_infection)\n",
    "    S_init, I_init = network_state(graph)\n",
    "\n",
    "    N = graph.number_of_nodes()\n",
    "    N_f = float(N)\n",
    "    S_list, I_list, R_list = [int(S_init)], [int(I_init)], [0]\n",
    "\n",
    "    for i in range(no_iterations):\n",
    "        SIR_batch(graph)\n",
    "        states = graph.ndata['STATE']\n",
    "        S, I, R = int((states == SUSCEPTIBLE).sum()), int((states == INFECTED).sum()), int((states == RECOVERED).sum())\n",
    "        S_list.append(S), I_list.append(I), R_list.append(R)\n",
    "        if I == 0:\n",
    "            # SIR simulation ended\n",
    "            break\n",
    "\n",
    "    # print(f\"Iteration {i+1}: S: {S} \\t I: {I} \\t R: {R}\")\n",
    "    return S_list, I_list, R_list, first_infected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE FOR ERDOS-RENYI GRAPH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "run simulation and store \n",
    "    1) state of all nodes at each time step\n",
    "    into a single pandas dataframe for all beta, gamma and repetitions\n",
    "    2) R_0\n",
    "    3) number of total people infected (total - susceptible at the end of the iteration) \n",
    "'''            \n",
    "seed = 38\n",
    "torch.manual_seed(seed)\n",
    "device = 'cpu'\n",
    "\n",
    "beta_range = [0, 1]\n",
    "gamma_range = [0.1, 1]\n",
    "iterations = 500\n",
    "\n",
    "no_graph_samples = 100\n",
    "no_realizations = 1000\n",
    "\n",
    "family_name = 'erdos_renyi'        \n",
    "folder = Path(f'{family_name}')\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "def simulate(p, graph_size, graph_sample, graphs_folder):\n",
    "    \n",
    "    json_filepath = str(Path(graphs_folder, f'data_{graph_sample}.json'))\n",
    "    graph_filename = graphs_folder / Path(f'sample{graph_sample}.bin')\n",
    "\n",
    "    json_data = {'family': family_name,\n",
    "                 'p': p,\n",
    "                 'graph_size': graph_size,\n",
    "                 'no_graph_samples': no_graph_samples,\n",
    "                 'graph_samples': []\n",
    "                }\n",
    "\n",
    "    sample = {'graph_filename': str(graph_filename),\n",
    "              'simulations': []}\n",
    "\n",
    "    if not os.path.exists(graph_filename):\n",
    "        graph = create_erdos_renyi_graph(graph_size, p)\n",
    "        save_graphs(str(graph_filename), graph)\n",
    "    else:\n",
    "        graph = load_graphs(str(graph_filename))[0][0]\n",
    "\n",
    "    graph.to(torch.device(device))\n",
    "    \n",
    "    if not os.path.exists(json_filepath):\n",
    "        for realizations in range(no_realizations):\n",
    "\n",
    "            beta = float(torch.FloatTensor(1).uniform_(beta_range[0], beta_range[1]))\n",
    "            gamma = float(torch.FloatTensor(1).uniform_(gamma_range[0], gamma_range[1]))\n",
    "            R0 = beta/gamma\n",
    "\n",
    "            graph.register_message_func(lambda x: SIR_message_func(beta, x))\n",
    "            graph.register_reduce_func(lambda x: SIR_reduce_func(gamma, x))\n",
    "\n",
    "            for initial_probability_of_infection in [0.01, 0.05, 0.1]:\n",
    "\n",
    "                simulation = {'beta': beta, 'gamma': gamma, 'R0': R0, 'init_infection_prob': initial_probability_of_infection}\n",
    "\n",
    "                S, I, R, first_infected = simulate_SIR(graph, initial_probability_of_infection, iterations)\n",
    "                simulation['S'] = S\n",
    "                simulation['I'] = I\n",
    "                simulation['R'] = R\n",
    "                simulation['first_infected'] = first_infected\n",
    "                simulation['total_infected'] = graph_size - S[-1]\n",
    "                sample['simulations'].append(deepcopy(simulation))\n",
    "                                \n",
    "                #print(\"Realization \", realizations, \"produced \", graph_size - S[-1], \"infected\")\n",
    "\n",
    "        json_data['graph_samples'].append(sample)\n",
    "        \n",
    "        with open(json_filepath, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "        with open(json_filepath, 'r') as f:\n",
    "            json.load(f)\n",
    "\n",
    "\n",
    "debug = False\n",
    "processes = 100\n",
    "import concurrent.futures\n",
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=processes)\n",
    "\n",
    "for graph_size in [10, 50, 100, 200, 500, 1000]:\n",
    "    for p in [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]:\n",
    "        graphs_folder = folder / Path(f'graphs_size{graph_size}_p{float(p)}')\n",
    "\n",
    "        #store each graph in a different folder (create path based on graph size, prob of edge and graph sample)\n",
    "        if not os.path.exists(graphs_folder):\n",
    "            os.makedirs(graphs_folder)\n",
    "\n",
    "        for graph_sample in range(no_graph_samples):  \n",
    "\n",
    "            if not debug:\n",
    "                pool.submit(simulate, p, graph_size, graph_sample, graphs_folder)\n",
    "            else:  # DEBUG\n",
    "                simulate(p, graph_size, graph_sample, graphs_folder)\n",
    "\n",
    "pool.shutdown()  # wait the batch of configs to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.01]:#[0.01, 0.05, 0.1, 0.2]:\n",
    "    for graph_size in [10, 50, 100, 200, 500, 1000]:\n",
    "        graphs_folder = folder / Path(f'graphs_size{graph_size}_p{float(p)}')\n",
    "\n",
    "            \n",
    "        R0_s = []\n",
    "        infected_s = []\n",
    "        for graph_sample in range(no_graph_samples):  \n",
    "            print('Processing sample', graph_sample)\n",
    "            json_filepath = str(Path(graphs_folder, f'data_{graph_sample}.json'))\n",
    "            graph_filename = graphs_folder / Path(f'sample{graph_sample}.bin')\n",
    "            \n",
    "            # graph = load_graphs(str(graph_filename))\n",
    "            with open(json_filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            simulations = data['graph_samples'][0]['simulations']  # only one element in this list\n",
    "            df = pd.DataFrame(simulations)\n",
    "            \n",
    "            for initial_probability_of_infection in [0.1]:#, 0.05, 0.1]:\n",
    "                filtered = df[df['init_infection_prob']==initial_probability_of_infection]\n",
    "                R0_s.extend(filtered['R0'])\n",
    "                infected_s.extend(filtered['total_infected'])\n",
    "                \n",
    "        sns.jointplot(R0_s, infected_s)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "                \n",
    "                \n",
    "            # debug\n",
    "            #break\n",
    "        # debug\n",
    "        break\n",
    "    # debug\n",
    "    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
