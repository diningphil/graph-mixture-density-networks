# Dataset and Splits
data_root: DATA
dataset_class: gmdn_dataset.AlchemyZINCDatasetInterface
dataset_name:  ZINC_full
data_splits_file:  DATA_SPLITS/ZINC_full/ZINC_full_outer1_inner1.splits


# Hardware
device:  cuda
max_cpus:  8
max_gpus: 1
gpus_per_task:  1


# Data Loading
dataset_getter: pydgn.data.provider.DataProvider
data_loader:
  class_name: torch_geometric.loader.DataLoader
  args:
    num_workers : 4
    pin_memory: True


# Reproducibility
seed: 42


# Experiment
result_folder: RESULTS
exp_name: gmdn_exp
experiment: pydgn.experiment.supervised_task.SupervisedTask
higher_results_are_better: True
evaluate_every: 1
final_training_runs: 3

grid:
  supervised_config:
    model: gmdn.GMDN
    checkpoint: True
    shuffle: True
    batch_size: 8192
    epochs: 2500

    number_of_experts:
      - 3
      - 5
    expert_hidden_units: 0
    hidden_units:
      - 64
    num_convolutional_layers:
      - 2
      - 5
      - 7
    dirichlet_alpha:
      - 1.0
      - 1.05
    neighborhood_aggregation: add
    output_type: gaussian
    aggregation:  # global aggregation
      - sum
      - mean

    # ------------------------ #

    engine:
      - pydgn.training.engine.TrainingEngine

    loss:
      - gmdn_loss.GMDNLoss

    scorer:
      - class_name: pydgn.training.callback.metric.MultiScore
        args:
          # used at model selection time. Should be the one on which to perform early stopping
          main_scorer: gmdn_score.LogLikelihoodScore
          metric2: gmdn_score.DirichletPriorScore
          metric3: gmdn_score.MeanAverageError

    readout: gmdn_emission.GraphExpertEmission

    optimizer:
      - class_name: pydgn.training.callback.optimizer.Optimizer
        args:
          optimizer_class_name: torch.optim.Adam
          lr:
             - 0.0001
          weight_decay: 0.  # Useful to constrain magnitude of weights.
          accumulate_gradients: True  # to implement G-EM

    early_stopper:
      - class_name:
          - pydgn.training.callback.early_stopping.PatienceEarlyStopper
        args:
          patience:
            - 30
          monitor: validation_Log Likelihood
          mode: max
          checkpoint: True

    plotter: pydgn.training.callback.plotter.Plotter
